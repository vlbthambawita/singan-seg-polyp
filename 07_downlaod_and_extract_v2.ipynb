{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib, os\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "from zipfile import ZipFile\n",
    "import time\n",
    "import yaml\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_path = \"/home/vajira/DL/singan-polyp-aug/config.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(yaml_path) as f:\n",
    "    output = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'links': {'link1': 'https://www.dropbox.com/s/yc3tn8sgn3m0v3r/TrainedModels_1_clean.zip?dl=1',\n",
       "  'link2': 'https://www.dropbox.com/s/0i7io4tkpoccmq4/TrainedModels_2_clean.zip?dl=1',\n",
       "  'link3': 'https://www.dropbox.com/s/hsdpkifid9prtst/TrainedModels_3_clean.zip?dl=1',\n",
       "  'link4': 'https://www.dropbox.com/s/hzu470zcmy5ygf1/TrainedModels_4_clean.zip?dl=1'}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_configs()->dict:\n",
    "    \n",
    "    with open(\"config.yaml\") as f:\n",
    "        output = yaml.safe_load(f)\n",
    "    f.close()\n",
    "    \n",
    "    return dict(output)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = load_configs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'link1': 'https://www.dropbox.com/s/yc3tn8sgn3m0v3r/TrainedModels_1_clean.zip?dl=1',\n",
       " 'link2': 'https://www.dropbox.com/s/0i7io4tkpoccmq4/TrainedModels_2_clean.zip?dl=1',\n",
       " 'link3': 'https://www.dropbox.com/s/hsdpkifid9prtst/TrainedModels_3_clean.zip?dl=1',\n",
       " 'link4': 'https://www.dropbox.com/s/hzu470zcmy5ygf1/TrainedModels_4_clean.zip?dl=1'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configs[\"links\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_zip_file(zip_path:str, dst_dir:str):\n",
    "    \n",
    "    print(\"=== Extracting files ===\")\n",
    "    time.sleep(2)\n",
    "    with ZipFile(file=zip_path) as zip_file:\n",
    "\n",
    "        # Loop over each file\n",
    "        for file in tqdm(iterable=zip_file.namelist(), total=len(zip_file.namelist())):\n",
    "\n",
    "            # Extract each file to another directory\n",
    "            # If you want to extract to current working directory, don't specify path\n",
    "            zip_file.extract(member=file, path=dst_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_extract_single_file(url:str, path_to_extract:str, extracting:bool = True, clean:bool =False):\n",
    "    \n",
    "    response = getattr(urllib, 'request', urllib).urlopen(url)\n",
    "    \n",
    "    filesize = int(response.headers.get('content-length', 0))#int(requests.head(url).headers[\"Content-Length\"])\n",
    "    chunk_size = 1024\n",
    "    \n",
    "    filename = os.path.basename(url).split(\"?\")[0]\n",
    "    os.makedirs(path_to_extract, exist_ok=True)\n",
    "    \n",
    "    abs_path = os.path.join(path_to_extract, filename)\n",
    "    \n",
    "    directory = abs_path[:-4]\n",
    "    \n",
    "    #print(directory)\n",
    "    \n",
    "    if os.path.exists(directory) and os.path.isdir(directory):\n",
    "        print(f\"The directory:{directory} is already exists.\")\n",
    "        return directory\n",
    "    \n",
    "    elif os.path.exists(abs_path):\n",
    "        print(f\"The zip file: {abs_path} is already exists.\")\n",
    "        \n",
    "        if extracting:\n",
    "            print(\"Extracting TRUE...!\")\n",
    "            extract_zip_file(abs_path, path_to_extract)\n",
    "        return directory\n",
    "    \n",
    "    else:\n",
    "    \n",
    "   \n",
    "        with requests.get(url, stream=True) as r, open(abs_path, \"wb\") as f, tqdm(\n",
    "            unit=\"B\",  # unit string to be displayed.\n",
    "            unit_scale=True,  # let tqdm to determine the scale in kilo, mega..etc.\n",
    "            unit_divisor=1024,  # is used when unit_scale is true\n",
    "            total=filesize,  # the total iteration.\n",
    "            file=sys.stdout,  # default goes to stderr, this is the display on console.\n",
    "            desc=filename  # prefix to be displayed on progress bar.\n",
    "        ) as progress:\n",
    "            for chunk in r.iter_content(chunk_size=chunk_size):\n",
    "                # download the file chunk by chunk\n",
    "                datasize = f.write(chunk)\n",
    "                # on each chunk update the progress bar.\n",
    "                progress.update(datasize)\n",
    "        f.close()\n",
    "        \n",
    "        if extracting:\n",
    "            print(\"Extracting TRUE...!\")\n",
    "            extract_zip_file(abs_path, path_to_extract)\n",
    "        \n",
    "    if clean:\n",
    "        os.remove(abs_path)\n",
    "        \n",
    "    return directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_checkpoints(path_to_checkpoints:str, link_keys=[\"link1\", \"link2\"],*args, **kwargs)-> str:\n",
    "    \n",
    "    all_links = load_configs()[\"links\"]\n",
    "    \n",
    "    for link_key in link_keys:\n",
    "        print(all_links[link_key])\n",
    "        download_link = all_links[link_key]\n",
    "        \n",
    "        download_and_extract_single_file(download_link, path_to_checkpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.dropbox.com/s/yc3tn8sgn3m0v3r/TrainedModels_1_clean.zip?dl=1\n",
      "The directory:/home/vajira/DL/temp_data/TrainedModels_1_clean is already exists.\n",
      "https://www.dropbox.com/s/0i7io4tkpoccmq4/TrainedModels_2_clean.zip?dl=1\n",
      "The directory:/home/vajira/DL/temp_data/TrainedModels_2_clean is already exists.\n"
     ]
    }
   ],
   "source": [
    "prepare_checkpoints(\"/home/vajira/DL/temp_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_new",
   "language": "python",
   "name": "pytorch_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
