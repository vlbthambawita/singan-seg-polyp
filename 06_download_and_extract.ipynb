{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/vajira/DL/singan-polyp-aug'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib, os\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "from zipfile import ZipFile\n",
    "import time\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eg_link = \"https://www.dropbox.com/s/67iz7xyo5v69lxl/TrainedModels_1_clean.zip\"\n",
    "dropbox_link_2 = \"https://www.dropbox.com/s/67iz7xyo5v69lxl/TrainedModels_1_clean.zip?dl=1\"\n",
    "#osf_link = \"https://files.osf.io/v1/resources/xrgz8/providers/dropbox/TrainedModels_1_clean.zip\"\n",
    "dst_dir = \"/home/vajira/DL/temp_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#r = requests.get(eg_link, allow_redirects=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_link = \"https://www.dropbox.com/s/lm38ld52k4enrj5/Zs.pth?dl=1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = getattr(urllib, 'request', urllib).urlopen(test_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "606811"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getattr(response, \"length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "58it [00:00, 8711.54it/s]\n"
     ]
    }
   ],
   "source": [
    "with open(\"/home/vajira/DL/temp_data/test.pth\", \"wb\") as f:\n",
    "    for chunk in tqdm(response):\n",
    "        f.write(chunk)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vajira/DL/temp_datatest.pth:   0%|          | 0.00/361k [00:00<?, ?B/s]\n"
     ]
    }
   ],
   "source": [
    "#eg_link = \"https://caspersci.uk.to/matryoshka.zip\"\n",
    "\n",
    "with tqdm.wrapattr(open(os.devnull, \"wb\"), \"write\",\n",
    "                   miniters=1, desc=dst_dir + \"test.pth\",\n",
    "                   total=getattr(response, 'length', None)) as fout:\n",
    "    for chunk in response:\n",
    "        fout.write(chunk)\n",
    "        print(\"fout\")\n",
    "\n",
    "fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vajira/DL/temp_dataZs.pth?dl=1: 100%|██████████| 593k/593k [00:00<00:00, 3.94MB/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "eg_link = \"https://www.dropbox.com/s/lm38ld52k4enrj5/Zs.pth?dl=1\"\n",
    "response = requests.get(eg_link, stream=True)\n",
    "with tqdm.wrapattr(open(os.devnull, \"wb\"), \"write\",\n",
    "                   miniters=1, desc=dst_dir + eg_link.split('/')[-1],\n",
    "                   total=int(response.headers.get('content-length', 0))) as fout:\n",
    "    for chunk in response.iter_content(chunk_size=4096):\n",
    "        fout.write(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'desc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-04a7291ad527>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdesc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'desc' is not defined"
     ]
    }
   ],
   "source": [
    "desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/vajira/DL/temp_data/TrainedModels_1_clean.zip\"\n",
    "path_to_extract = \"/home/vajira/DL/temp_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/vajira/DL/temp_data/TrainedModels_1_clean.zip'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-e77cac2b0f61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Open your .zip file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mzip_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Loop over each file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamelist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamelist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_new/lib/python3.6/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64)\u001b[0m\n\u001b[1;32m   1111\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1113\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1114\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/vajira/DL/temp_data/TrainedModels_1_clean.zip'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Open your .zip file\n",
    "with ZipFile(file=path) as zip_file:\n",
    "\n",
    "    # Loop over each file\n",
    "    for file in tqdm(iterable=zip_file.namelist(), total=len(zip_file.namelist())):\n",
    "\n",
    "        # Extract each file to another directory\n",
    "        # If you want to extract to current working directory, don't specify path\n",
    "        zip_file.extract(member=file, path=path_to_extract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib, os\n",
    "from tqdm import tqdm\n",
    "urllib = getattr(urllib, 'request', urllib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TqdmUpTo(tqdm):\n",
    "    \"\"\"Provides `update_to(n)` which uses `tqdm.update(delta_n)`.\"\"\"\n",
    "    def update_to(self, b=1, bsize=1, tsize=None):\n",
    "        \"\"\"\n",
    "        b  : int, optional\n",
    "            Number of blocks transferred so far [default: 1].\n",
    "        bsize  : int, optional\n",
    "            Size of each block (in tqdm units) [default: 1].\n",
    "        tsize  : int, optional\n",
    "            Total size (in tqdm units). If [default: None] remains unchanged.\n",
    "        \"\"\"\n",
    "        if tsize is not None:\n",
    "            self.total = tsize\n",
    "        return self.update(b * bsize - self.n)  # also sets self.n = b * bsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Zs.pth?dl=1: 100%|██████████| 600k/600k [00:02<00:00, 257kB/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "614400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "eg_link = \"https://www.dropbox.com/s/lm38ld52k4enrj5/Zs.pth?dl=1\"\n",
    "with TqdmUpTo(unit='B', unit_scale=True, unit_divisor=1024, miniters=1,\n",
    "              desc=eg_link.split('/')[-1]) as t:  # all optional kwargs\n",
    "    urllib.urlretrieve(eg_link, filename=os.devnull,\n",
    "                       reporthook=t.update_to, data=None)\n",
    "    t.total = t.n\n",
    "    print(t.total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working downlaod with progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pathlib import Path\n",
    "import os\n",
    "import requests\n",
    "import sys\n",
    " \n",
    " \n",
    "url = \"https://www.dropbox.com/s/lm38ld52k4enrj5/Zs.pth?dl=1\"\n",
    "filename = os.path.basename(url).split(\"?\")[0]\n",
    "dst_dir = \"/home/vajira/DL/temp_data\"\n",
    "os.makedirs(dst_dir, exist_ok=True)\n",
    "abs_path = os.path.join(dst_dir, filename)\n",
    "#with requests.get(url, stream=True) as r, open(abs_path, \"wb\") as f:\n",
    "#    for chunk in r.iter_content(chunk_size=1024):\n",
    "#        f.write(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/vajira/DL/temp_data/Zs.pth'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "filesize = int(response.headers.get('content-length', 0))#int(requests.head(url).headers[\"Content-Length\"])\n",
    "chunk_size = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zs.pth: 100%|██████████| 593k/593k [00:00<00:00, 903kB/s] \n"
     ]
    }
   ],
   "source": [
    "with requests.get(url, stream=True) as r, open(abs_path, \"wb\") as f, tqdm(\n",
    "        unit=\"B\",  # unit string to be displayed.\n",
    "        unit_scale=True,  # let tqdm to determine the scale in kilo, mega..etc.\n",
    "        unit_divisor=1024,  # is used when unit_scale is true\n",
    "        total=filesize,  # the total iteration.\n",
    "        file=sys.stdout,  # default goes to stderr, this is the display on console.\n",
    "        desc=filename  # prefix to be displayed on progress bar.\n",
    ") as progress:\n",
    "    for chunk in r.iter_content(chunk_size=chunk_size):\n",
    "        # download the file chunk by chunk\n",
    "        datasize = f.write(chunk)\n",
    "        # on each chunk update the progress bar.\n",
    "        progress.update(datasize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_zip_file(zip_path:str, dst_dir:str):\n",
    "    \n",
    "    print(\"=== Extracting files ===\")\n",
    "    time.sleep(2)\n",
    "    with ZipFile(file=zip_path) as zip_file:\n",
    "\n",
    "        # Loop over each file\n",
    "        for file in tqdm(iterable=zip_file.namelist(), total=len(zip_file.namelist())):\n",
    "\n",
    "            # Extract each file to another directory\n",
    "            # If you want to extract to current working directory, don't specify path\n",
    "            zip_file.extract(member=file, path=dst_dir)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_extract_single_file(path_to_extract:str, url:str, extracting:bool = True, clean:bool =True):\n",
    "    \n",
    "    response = getattr(urllib, 'request', urllib).urlopen(url)\n",
    "    \n",
    "    filesize = int(response.headers.get('content-length', 0))#int(requests.head(url).headers[\"Content-Length\"])\n",
    "    chunk_size = 1024\n",
    "    \n",
    "    filename = os.path.basename(url).split(\"?\")[0]\n",
    "    os.makedirs(path_to_extract, exist_ok=True)\n",
    "    \n",
    "    abs_path = os.path.join(dst_dir, filename)\n",
    "    \n",
    "    directory = abs_path[:-4]\n",
    "    \n",
    "    #print(directory)\n",
    "    \n",
    "    if os.path.exists(directory) and os.path.isdir(directory):\n",
    "        print(f\"The directory:{directory} is already exists.\")\n",
    "        return directory\n",
    "    \n",
    "    if os.path.exists(abs_path):\n",
    "        print(f\"The zip file: {abs_path} is already exists.\")\n",
    "        \n",
    "        if extracting:\n",
    "            print(\"Extracting TRUE...!\")\n",
    "            extract_zip_file(abs_path, path_to_extract)\n",
    "        return directory\n",
    "    \n",
    "   \n",
    "    with requests.get(url, stream=True) as r, open(abs_path, \"wb\") as f, tqdm(\n",
    "        unit=\"B\",  # unit string to be displayed.\n",
    "        unit_scale=True,  # let tqdm to determine the scale in kilo, mega..etc.\n",
    "        unit_divisor=1024,  # is used when unit_scale is true\n",
    "        total=filesize,  # the total iteration.\n",
    "        file=sys.stdout,  # default goes to stderr, this is the display on console.\n",
    "        desc=filename  # prefix to be displayed on progress bar.\n",
    "    ) as progress:\n",
    "        for chunk in r.iter_content(chunk_size=chunk_size):\n",
    "            # download the file chunk by chunk\n",
    "            datasize = f.write(chunk)\n",
    "            # on each chunk update the progress bar.\n",
    "            progress.update(datasize)\n",
    "    f.close()\n",
    "    \n",
    "\n",
    "    if clean:\n",
    "        os.remove(abs_path)\n",
    "        \n",
    "    return directory\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The directory:/home/vajira/DL/temp_data/TrainedModels_1_clean is already exists.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/vajira/DL/temp_data/TrainedModels_1_clean'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download_and_extract_single_file(dst_dir, dropbox_link_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2514/2514 [00:16<00:00, 157.02it/s]\n"
     ]
    }
   ],
   "source": [
    "path= \"/home/vajira/DL/temp_data/TrainedModels_1_clean.zip\"\n",
    "path_to_extract = \"/home/vajira/DL/temp_data/\"\n",
    "# Open your .zip file\n",
    "with ZipFile(file=path) as zip_file:\n",
    "\n",
    "    # Loop over each file\n",
    "    for file in tqdm(iterable=zip_file.namelist(), total=len(zip_file.namelist())):\n",
    "\n",
    "        # Extract each file to another directory\n",
    "        # If you want to extract to current working directory, don't specify path\n",
    "        zip_file.extract(member=file, path=path_to_extract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_checkpoints(path_to_checkpoints:str, *args, **kwargs)-> str:\n",
    "    pass\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_new",
   "language": "python",
   "name": "pytorch_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
